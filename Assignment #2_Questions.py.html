
# coding: utf-8

# <div style="text-align: center;">
# <h2>INFSCI 2595 Machine Learning - Fall 2018 </h2>
# <h1 style="font-size: 250%;">Assignment #2</h1>
# <h3>Due Sunday, 11:59am, 11/18/2018</h3>
# <h3>Total points: 100 </h3>
# </div>

# In[1]:


# Type in your information in the double quotes
firstName = "Guojing"
lastName = "Zhang"
pittID = "guz23"


# # <h3>  Problem #1. Linear Discriminant Analysis (LDA)and Quadratic Discriminant Analysis(QDA) </h3> 
#  ### [30 points]
#  
# Do not write a code for this part

# <h4> Problem #1-1 [10 points]</h4>  <br>
# We have a classification problem with one feature $(x)$ and K classes to be classified. The prior probability of
# class $k$ is $ùúã_{k} = ùëÉ(ùëå = ùëò)$. Assume that the feature in class k has Gaussian distribution of
# mean $Œº_{k}$ and variance $œÉ^2 (ùí©(Œº,ùúé^{2}))$.The variance is the same for all classes. 
# Prove that the Bayes‚Äô classifier (that chooses class k with largest $ùëÉ(ùëå = ùëò|ùë•))$ is equivalent to assigning an observation to the class for which the discriminant function $ùõø_{k}(x)$ is
# maximized, where 
# \begin{array} \\
# ùõø_{k}(x) = x\frac{\mu _{k}}{\sigma ^{2}}- \frac{\mu_{2}^{k}}{2\sigma ^{2}}+ log(\pi _{k})
# \end{array}
# <br> What is the name of this classifier?

# <h4> The name is Linear Discriminant Analysis </h4>

# ![%E6%89%AB%E6%8F%8F%E5%AE%9D%E6%96%87%E6%A1%A3%E5%88%9B%E5%BB%BA%E4%BA%8E2018%E5%B9%B411%E6%9C%8818%E6%97%A5%20%E4%B8%8B%E5%8D%888_22_59.png](attachment:%E6%89%AB%E6%8F%8F%E5%AE%9D%E6%96%87%E6%A1%A3%E5%88%9B%E5%BB%BA%E4%BA%8E2018%E5%B9%B411%E6%9C%8818%E6%97%A5%20%E4%B8%8B%E5%8D%888_22_59.png)

# <h4> Problem #1-2 [15 points]</h4>  <br>
# Extend **Problem #1-1** to include **p** features. With features from each class drawn from a
# Gaussian distribution with mean vector $Œº_{k}$ and covariance matrix $Œ£_{k}$ (which is now
# different for each class). What is the discriminant function that maximizes **ùëÉ(ùëå = ùëò|ùë•)**. Is
# the relationship with the feature vector **x** linear?<br> What is this classifier?

# ![%E6%89%AB%E6%8F%8F%E5%AE%9D%E6%96%87%E6%A1%A3%E5%88%9B%E5%BB%BA%E4%BA%8E2018%E5%B9%B411%E6%9C%8818%E6%97%A5%20%E4%B8%8B%E5%8D%888_45_06.png](attachment:%E6%89%AB%E6%8F%8F%E5%AE%9D%E6%96%87%E6%A1%A3%E5%88%9B%E5%BB%BA%E4%BA%8E2018%E5%B9%B411%E6%9C%8818%E6%97%A5%20%E4%B8%8B%E5%8D%888_45_06.png)

# <h4> not a linear with feature vector x. the classifier is quadratic Discriminant Analysis </h4>

# <h4> Problem #1-3 [5 points]</h4>  <br>
# - Explain Bias and variance trade-off between the two above classifiers.

# <h4> The LDA is simpler than QDA, but will lead to high bias. The QDA is complex than LDA, the model have higher flexibility, but may cause overfitting.</h4>

# #### <h3>  Problem #2. Regularization    </h3>
# ### [15 points]

# <h4> Problem #2-1. [3 points]</h4> Answer the following questions 
# 
# - What is the main purpose of using regularization?
# 

# <h4> It's to avoid overfitting, by shrinking the coefficient estimates towards zero. </h4>

# <h4> Problem #2-2.Logistic Regression with Ridge Regularization [12 points] </h4>  <br>
# 
# In this part, you should download and analyze the Wisconson **"breast_cancer"** dataset. <br>
# 
# - Fit logistic regression model using ridge regularization with different values of  C = 0.1, 1, 5, 10, 50, 100, and 1000 (Note that C is the LogisticRegression function argument). For each value, report the estimated coefficients for the fitted model (do not just print summary, make a table with feature names and estimated coefficients)
# 
# - What happens to the coefficients as you increase C?
# 
# - What happens to the flexibility of the model as you increase C?

# In[2]:


from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import pandas as pd
import numpy as np
data = load_breast_cancer()

X_train, X_test, Y_train, Y_test = train_test_split(data.data,data.target,random_state = 0)
c = [0.1, 1, 5, 10, 50, 100,1000]
res = []
for i in c:
    RegModel = LogisticRegression(penalty='l2',C=i,random_state=0).fit(X_train,Y_train)
    res.append(RegModel.coef_[0])
print("I have no idea why the result changes at the basis I have set the random state. I tried google it, but the problem didn't solved.")
pd.DataFrame(res,index=[0.1, 1, 5, 10, 50, 100,1000],columns=data.feature_names)


# <h4> when we increase the c, it means the the less regularization. The absolute of coefficients becomes bigger. </h4>

# <h4> When we increase c, the coefficient becomes biggers, the model becomes more complex and higher flexibility. </h4>

# ### <h3>  Problem #3. Logistic Regression and Unbalanced Datasets  </h3> 
# ### [25 points]

# 
# We fit a logistic regression model to predict the probability that an individual will default on his/her credit card balance. We used the total balance (single feature) to fit the model and got the results shown in the table below.

# <h4> Problem #3-1. [5 points]</h4> Prediciton with Logistic regression <br>

# |Table|Coefficient|Std.error|Z-statistic|P-Value|
# |:--:|:-------------------------------:|
# |Intercept|-10.6513|0.3612|-29.5|<0.0001|
# |balance|0.0055|0.002|24.9|<0.0001|

# (You can refer to page 14 in the our slides "Logistic Regression.pdf" if the above table does not show well.)

# - What is the parametric model used in logistic regression?
# - What is the class label of an individual with a balance equals to 15,000 dollar? What is the class label of an individual with balance equals to 800 dollar? (Write a python function which takes two inputs (feature, model_parameters) and returns the class labels for the data). default is class 1 and non-default is class 0.

# <h4> using linear regression model and has a logit that is linear with x </h4>

# In[26]:


import math
def LR(feature, p):
    exp = math.exp(p[0] + feature * p[1])
    res = exp / (1 + exp)
    if res >= 0.5:
        return 1
    else:
        return 0
p = [-10.6513, 0.0055] 

print("the class label of individual with 800 dollar balance is ",LR(800,p))
print("the class label of individual with 15000 dollar balance is ",LR(15000,p))


# <h4> Problem #3-2. [10 points]</h4>  <br>
# 
# The coefficients of logistic regression are obtained by maximizing the likelihood function
# 
# \begin{array} \\
# l(\beta) = \prod_{i:y_{i}=1} P(y_{i} = 1|x)\prod_{i{}':y_{{i}'}=0} (1-P(y_{{i}'} = 1|x))
# \end{array}
# Show that maximizing the
# likelihood function is equivalent to minimizing the cost function $J(\beta)$, such that.
# \begin{array} \\
# J(\beta) = -\sum [y_{i} log(P(y_{i} = 1|x)) + (1- y_{i})log(1- P(y_{i} = 1|x))]
# \end{array}
# 
# 
# Here $n$ is the number training examples. Mention one possible method for obtaining the
# optimal coefficients.

# ![%E6%89%AB%E6%8F%8F%E5%AE%9D%E6%96%87%E6%A1%A3%E5%88%9B%E5%BB%BA%E4%BA%8E2018%E5%B9%B411%E6%9C%8818%E6%97%A5%20%E4%B8%8B%E5%8D%885_22_53.png](attachment:%E6%89%AB%E6%8F%8F%E5%AE%9D%E6%96%87%E6%A1%A3%E5%88%9B%E5%BB%BA%E4%BA%8E2018%E5%B9%B411%E6%9C%8818%E6%97%A5%20%E4%B8%8B%E5%8D%885_22_53.png)
# 

# <h4> gradient descent </h4>

# <h4> Problem #3-3 [10 points]</h4> <br>
# In a fraud detection system, a QDA classifier‚Äôs confusion matrix is found to be:

# |        |Predicted Class - Not fraud| Predicted Class - fraud|
# |:--:|:-------------------------------:|
# |Actual class ‚Äì Not fraud|1200|25|
# |Actual class ‚Äì fraud|30|7|

# - Is dataset balanced? Why?
# - Evaluate the overall error rate <br>
# - Evaluate the precision and the recall <br>
# 

# <h4> this dataset is imbalanced, because the amount of not fraut class is much more bigger than the fraud class. </h4>

# In[47]:


su = 1200 + 25+ 30+7
accu = 1200 + 7
error = 1 - (accu/su)
print("The error rate is ",error)


# In[48]:


pos = 25+7
tru = 7
print("The precision is ",tru/pos)


# In[49]:


print("The recall is ",7/(30+7))


# ### <h3>  Problem #4. SVM, Decision Trees, MLP Classification   </h3> 
# ### [30 points]

# In this problem, you will use different classification methods, SVM, Decision Tree and MLP; and find their accuracies using the test data. 
# We will also use the Wisconson **"breast_cancer"** dataset.
# In all of the following subparts, use random_state=0 when you split the dataset into train and test and **standardize** the data.

# In[3]:


# write your code here
import numpy as np
import pandas as pd
from sklearn import datasets 
from sklearn.metrics import confusion_matrix, precision_score, recall_score
from sklearn.model_selection import train_test_split 
from sklearn.datasets import load_breast_cancer
from sklearn.svm import SVC

dataset = load_breast_cancer()

X_train, X_test, y_train, y_test= train_test_split(dataset.data, dataset.target, random_state= 0)

# standardize data
from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler().fit(X_train)
X_train_transformed= scaler.transform(X_train)
X_test_transformed= scaler.transform(X_test)


# <h4> Problem #4-1.  Classification with SVM [10 points]</h4><br>
# - How does the Radial Basis Function Kernel in SVM measure the similarity between a test point and a training example?
# - Fit an SVM classifier with a radial basis function kernel, with gamma =0.1, and regularization parameter C set to 10. Use the classifier to predict class labels for the test data. 
# - Calculate the accuracy and confusion matrix on the test data.

# <h4> use a Gaussian-like similarity measure, compute the squared Euclidean distance between the test and training points. </h4>

# In[4]:


svmmodel = SVC(kernel='rbf',gamma=0.1,C=10).fit(X_train_transformed,y_train)
res = svmmodel.score(X_test_transformed,y_test)
print("The accuracy of SVM model is ",res)


# In[5]:


predictedOutput = svmmodel.predict(X_test_transformed)
confusion = confusion_matrix(y_test,predictedOutput)
pd.DataFrame(confusion)


# <h4> Problem #4-2.  Classification with Decisin Tree (DT) [10 points]</h4><br>
# - In this part, use DT classification method on the training data. Set the maximum depth of the tree to five. Then use the classifier to predict class labels for the test data. Calculate the accuracy and confusion matrix on the test data.
# - Use Adaboost to combine four decision trees each of max_depth of five. Use random_state=0 in adaboost. Find the test accuracy. 

# In[6]:


from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

treeModel = DecisionTreeClassifier(max_depth=5,random_state=0).fit(X_train_transformed,y_train)
res1 = treeModel.score(X_test_transformed,y_test)
print("The accuracy of decision tree is ",res1)
predictedOutput1 = treeModel.predict(X_test_transformed)
confusion1 = confusion_matrix(y_test,predictedOutput1)
pd.DataFrame(confusion1)


# In[7]:


BoostModel= AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),n_estimators=4,random_state=0).fit(X_train_transformed,y_train)
res2 = BoostModel.score(X_test_transformed,y_test)
print("The accuracy of boosting is ",res2)
predictedOutput2 = BoostModel.predict(X_test_transformed)
confusion2 = confusion_matrix(y_test,predictedOutput2)
pd.DataFrame(confusion2)


# <h4> Problem #4-3 [10 points]</h4>
# 
# Follow steps to answer questions to build a neural network using MLPClassifier from sklearn.neural_network. 
# - Build a model that has two hidden layers, the first layer has 10 neurons and second layer has 5 neurons. 
# - Use 'relu' activation function, and set the regularization parameter alpha=0.5. 
# - Set max_iter=1000; Set the random_state=0.
# - Use stochastic gradient descent (sgd) to solve the optimization  problem
# - Report accuracy, confusion matrix, precision, and recall 

# In[8]:


from sklearn.neural_network import MLPClassifier
MLPmodel = MLPClassifier(solver='sgd', activation='relu', random_state=0,
                         hidden_layer_sizes=[10,5], alpha=0.5, max_iter=1000).fit(X_train_transformed,y_train)
res = MLPmodel.score(X_test_transformed,y_test)
print("The accuracy of nn model is ",res)
predictedOutput3 = MLPmodel.predict(X_test_transformed)
confusion3 = confusion_matrix(y_test,predictedOutput3)
print("The precision score is ",precision_score(y_test,predictedOutput3))
print("The recall score is ",recall_score(y_test,predictedOutput3))
pd.DataFrame(confusion3)

